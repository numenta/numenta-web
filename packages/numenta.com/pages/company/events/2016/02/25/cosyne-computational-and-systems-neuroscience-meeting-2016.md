---
author: Numenta
brief:
date: 2016/02/25
event:
  what: A Theory of Sequence Memory in the Neocortex
  when:
    begin: 2016/02/25
    end: 2016/02/28
  where:
    desc: Marriott Downtown
    city: Salt Lake City
    state: UT
    country: USA
    web: http://www.cosyne.org/c/index.php?title=Cosyne_16
  who: Jeff Hawkins, Subutai Ahmad, Yuwei Cui, and Scott Purdy
  why: Poster Presentation
image: ../images/image.png
org: Research Team
tags: theory sequence memory neocortex cosyne 2016 computational and systems neuroscience numenta jeff hawkins
title: COSYNE 2016 Computational and Systems Neuroscience Meeting
type: post
---

## Abstract

#### A Theory of Sequence Memory in the Neocortex

Neocortical neurons have thousands of excitatory synapses. It is a mystery how
neurons integrate the input from so many synapses and what kind of large-scale
network behavior this enables. It has been previously proposed that non-linear
properties of dendrites enable neurons to recognize multiple patterns. In this
paper we extend this idea by showing that a neuron with several thousand
synapses arranged along active dendrites can learn to accurately and robustly
recognize hundreds of unique patterns of cellular activity, even in the presence
of large amounts of noise and pattern variation. We then propose a neuron model
where some of the patterns recognized by a neuron lead to action potentials and
define the classic receptive field of the neuron, whereas the majority of the
patterns recognized by a neuron act as predictions by slightly depolarizing the
neuron without immediately generating an action potential. We then present a
network model based on neurons with these properties and show that the network
learns a robust model of time-based sequences. Given the similarity of
excitatory neurons throughout the neocortex and the importance of sequence
memory in inference and behavior, we propose that this form of sequence memory
is a universal property of neocortical tissue. We further propose that cellular
layers in the neocortex implement variations of the same sequence memory
algorithm to achieve different aspects of inference and behavior. The neuron and
network models we introduce are robust over a wide range of parameters as long
as the network uses a sparse distributed code of cellular activations. The
sequence capacity of the network scales linearly with the number of synapses on
each neuron. Thus neurons need thousands of synapses to learn the many temporal
patterns in sensory stimuli and motor sequences.

Related links:
* [More Resources](/resources/papers-videos-and-more/)
* [PDF Whitepaper](/resources/papers/)

## About Cosyne

The annual Cosyne meeting provides an inclusive forum for the exchange of
experimental and theoretical/computational approaches to problems in systems
neuroscience.

To encourage interdisciplinary interactions, the main meeting is arranged in a
single track. A set of invited talks are selected by the Executive Committee and
Organizing Committee, and additional talks and posters are selected by the
Program Committee, based on submitted abstracts.

Cosyne topics include (but are not limited to): neural coding, natural scene
statistics, dendritic computation, neural basis of persistent activity,
nonlinear receptive field mapping, representations of time and sequence, reward
systems, decision-making, synaptic plasticity, map formation and plasticity,
population coding, attention, and computation with spiking networks.
Participants include pure experimentalists, pure theorists, and everything in
between.
